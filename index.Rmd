---
title: "Categorical Sequence Analysis with Optimal Matching: An Application with Data from the 'Women 40+ Healthy Aging Study'"
author: 'Adriana Clavijo Daza'
date: 'June 2023'
institution: 'University of Bern'
division: 'Faculty of Science'
advisor: 'Prof. Dr. David Ginsbourger'
altadvisor: 'Dr. Serena Lozza-Fiacco'
department: 'Institute of Mathematical Statistics and Actuarial Science'
degree: 'Master of Science in Statistics and Data Science'
knit: bookdown::render_book
# site: bookdown::bookdown_site

# The next two lines allow you to change the spacing in your thesis. You can 
# switch out \onehalfspacing with \singlespacing or \doublespacing, if desired.
header-includes:
    - \usepackage{setspace}\onehalfspacing
    - \usepackage{algpseudocode}
    - \usepackage{algorithm}
    - \AtBeginDocument{\renewcommand{\chaptername}{Section}}

# Remove the hashtag to specify which version of output you would like.
# Can only choose one at a time.
output:
  thesisdown::thesis_pdf: default 
#  thesisdown::thesis_gitbook: default         
#  thesisdown::thesis_word: default
#  thesisdown::thesis_epub: default

# If you are creating a PDF you'll need to write your preliminary content 
# (e.g., abstract, acknowledgements) below or use code similar to line 25-26 
# for the .RMD files. If you are NOT producing a PDF, delete or silence
# lines 25-39 in this YAML header.
abstract: |
  `r if(knitr:::is_latex_output()) paste(readLines("prelims/00-abstract.Rmd"), collapse = "\n  ")`

# If you'd rather include the preliminary content in files instead of inline
# like below, use a command like that for the abstract above.  Note that a tab 
# is needed on the line after the `|`.
acknowledgements: |
  First and foremost, I want to thank my coadvisors for their amazing guidance — which is the foundation of this work — and for the patience and understanding they showed towards me at every step of the way. I also want to thank my family for their support, specially Dani who gave me invaluable encouragement and help during this process. Finally, thanks to Lea and Nikita for being sources of inspiration.
dedication: |
 A la memoria de mi Lunita. 

# Note that abbreviations in lowercase letters will NOT be automatically
# capitalized.
# abbreviations:
#   ABC: American Broadcasting Company
#   CBS: Colombia Broadcasting System
#   CUS: Computer User Services
#   PBS: Public Broadcasting System
#   NBC: National Broadcasting Company

# Specify the location of the bibliography below
bibliography: bib/thesis.bib

# Download your specific csl file and refer to it in the line below.
csl: csl/apa.csl
lot: true
lof: true
---

<!--
Above is the YAML (YAML Ain't Markup Language) header that includes a lot of 
metadata used to produce the document.  Be careful with spacing in this header!

If you'd prefer to not include a Dedication, for example, simply delete the 
section entirely, or silence them (add # before each line). 

If you have other LaTeX packages you would like to include, delete the # before
header-includes and list the packages after hyphens on new lines.

If you'd like to include a comment that won't be produced in your resulting file
enclose it in a block like this.

If you receive a duplicate label error after knitting, make sure to delete the
index.Rmd file and then knit again.
-->

```{r packages, include = FALSE}
library(readxl)
library(tidyr)
library(dplyr)
library(stringr)
library(ggplot2)
library(TraMineR)
library(TraMineRextras)
library(cluster)
library(extrafont)
```

```{r helpers, include = FALSE}
## Note: this is order dependent.
source("helpers/distance_matrix.R", local = knitr::knit_global())
source("helpers/predict_scores.R", local = knitr::knit_global())
source("helpers/get_MSE.R", local = knitr::knit_global())
```

```{r setup, include = FALSE}
# Global knitr chunk options
## Note: updating global chunk options propagates, invalidating existing cache.
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  # Graphics settings
  fig.align = "center",
  fig.width = 7.5,
  fig.height = 5.25,
  ## Use cairo_pdf to embed fonts in the plots (and preserve it when rendering):
  ## https://stackoverflow.com/a/36663975
  dev = "cairo_pdf",
  ## Font family for base plots. Requires it available via extrafont::
  dev.args = list(family = "Latin Modern Math") ## For base plots.
)

extrafont::loadfonts(device = "all")
# GGplot theme.
ggplot2::theme_set(ggplot2::theme_minimal(base_size = 12))

ggplot2::theme_update(
  ## Default axis labels size is 80% of plot font size. Increasing to 100%.
  axis.text = ggplot2::element_text(size = ggplot2::rel(1)),
  ## Font family. Requires it available via extrafont::
  text = ggplot2::element_text(family = "Latin Modern Math")
)

options(width = 80)
```

<!--
The acknowledgments, preface, dedication, and abstract are added into the PDF
version automatically by inputting them in the YAML at the top of this file.
Alternatively, you can put that content in files like 00--prelim.Rmd and
00-abstract.Rmd like done below.
-->

```{r eval = !knitr::is_latex_output(), child = here::here("prelims", "00--prelim.Rmd")}
```

```{r eval = !knitr::is_latex_output(), child = here::here("prelims", "00-abstract.Rmd")}
```

```{r, child = "data_prep.Rmd"}
```

```{r, child = "main_analysis.Rmd"}
```

<!-- The {.unnumbered} option here means that the introduction will be 
"Chapter 0." You can also use {-} for no numbers on chapters.
-->

# Introduction {.unnumbered}

In order to extract useful information from a dataset of categorical sequences, we can obtain pair-wise distances between the data points and use a distance-based method which is particularly convenient when the complexity of the raw data is high. Depending on the objective of the researcher and the availability of other observed variables, we can apply an unsupervised or supervised learning technique. For example, we can obtain groups of similar sequences, identify common trajectories or predict other variables of interst. 

In computational linguistics, we encounter several methods to obtain these distances, for instance, there is a category of measures known as *edit distances* that are widely used for text prediction. To give some examples, the Hamming distance accounts for differences at each time point of a pair of sequences of the same length, or a dissimilarity measure can be defined based on the length of common subsequences or prefixes. One of the measures considered as an edit distance is the Levenshtein distance which finds the minimum number of steps required to arrive to one sequence taking the other as a starting point. The steps can be insertions, deletions or substitutions in the case of the Levenshtein distance, but other distances also consider the option of character swaps. 

In bioinformatics, a generalization of the Levenshtein distance was proposed by @Needleman-Wunsch-1970 to find similarities in the amino acid sequences of two proteins. The Needleman-Wunsch algorithm finds the best alignment of two sequences by maximizing the similarity between them with the possibility of different penalization values for substitutions. This algorithm was introduced and adapted to social sciences by @Abbott-1986, who denominated it optimal matching (OM). Since then, it has been extensively used to answer questions involving sociological processes that take values in a categorical set and occur along a specific period of time, mainly in the study of paths of family formation or professional careers (see @Abbott-2000).

One of the most common analysis strategy of several studies employing OM is to identify groups of trajectories that exhibit similar patterns based on the dissimilarities among categorical sequences. This is achieved through the application of clustering techniques to the distance matrix generated with help of the algorithm. However, a variety of unsupervised and supervised learning techniques can be applied to the distance matrix obtained via OM depending on the particular research question addressed. 

Furthermore, we want to draw special attention to the fact that, there are a number of decisions involved in the application of OM, namely the method for calculation of the *cost matrix* and their associated parameters or the normalization used to transform the distances to account for differences in their lengths. Moreover, we can interpret these decisions as hyperparameters that are subject to tunning.

In this work, we use a dataset that contains categorical sequences of the relationship and family formation history for a group of women. The time frame to be considered is from the age of 15 years to the current age at the time of data collection and the data was collected in the context of a larger research project denominated 'Women 40+ Healthy Aging Study'. The available data contains information about the civil status, relationship status, cohabitation status and maternity situation of the participants. In addition, the dataset encloses scores of personality traits that were obtained with a psychometric instrument. 

Our aim it to explore the effect that changing the aforementioned hyperparameters has on the distance matrix obtained via OM. In the absence of a methodological framework to directly compare distance matrices, we  consider the changes in the groups obtained via hierarchical clustering. On the other hand, we are interested in exploring the influence of the relationship and family history on the personality scores of the participants. For this purpose, we use a supervised learning technique and assess the quality of the prediction when the hyperparameters change. 

One of the main tools to perform our investigation is the implementation of the OM algorithm in the `R` package `TraMineR` (@TraMineR) as it provides several methods for data-based calculation of the cost matrix and functions to visualize categorical sequences.

The document is structured as follows: in Section \@ref(background) we give an account of the most commonly used edit distances, then we introduce the data we use in our application and explain the method chosen for prediction. In Section \@ref(om) we provide a detailed description of the OM algorithm, including the methods considered to obtain the cost matrix and the normalization methods for the distance matrix. In Section \@ref(data), we provide more insight on the data and perform OM to obtain clusters of sequences and use visualizations to provide a description of the groups. In Section \@ref(knn), we perform a first attempt at prediction of the personality scores based on the data from the previous section and, we show some of the additional scenarios considered, specifically those that produce the best predictions for each personality trait. Finally, as a conclusion, we present some conclusions and recommendations for future work.
