# Optimal Matching Algorithm {#om}

As mentioned above, OM is a technique widely applied in social sciences for the comparison of categorical sequences. OM uses the Needleman-Wunsch algorithm to identify similarities between biological sequences that are usually represented as strings of characters.

The goal of OM is to find the best possible alignment between two sequences by considering the differences and equivalences between their elements and minimizing the total cost associated. The cost of changing between states of the sequences we are interested in aligning, can be defined in several ways including data-based methods or values supplied by experts in the particular field.

Consider a set of $n$ categorical states $S = \{s_1, \dots, s_n\}$, we define $X = (x_1, \dots, x_t)$, a sequence of length $t_X < \infty$, where $x_i \in S$ for $i = 1, \dots, t_X$. Further, let $\mathbf{S}$ be the set of all possible sequences with states belonging to $S$.

Now, let $Y \in \mathbf{S}$ be a sequence of size $t_Y$. In order to numerically assess the disimilarity between the sequences $X$ and $Y$, an array $F$ of size $(t_X+1) \times (t_Y+1)$ is used to align the sequences $X$ and $Y$. Algorithm \@ref(OMalg) below shows the initialization and recursion to fill the array $F$.

\vspace{12pt}

\begin{algorithm}
\caption{Optimal matching.}
\label{OMalg}
\begin{algorithmic}[1]
\State $F(1, 1) \gets 0$
\For{$j \gets 2,t_Y+1$}
  \State $F(1,j) \gets F(1, j-1) + d$
\EndFor
\For{$i \gets 2,t_X+1$}
  \State $F(i,1) \gets F(i-1, 1) + d$
\EndFor
\For{$i \gets 2,t_X+1$}
  \For{$j \gets 2,t_Y+1$}
    \State $F(i,j) \gets \min\{F(i-1, j)+d, F(i, j-1)+d, F(i-1, j-1)+C(y_{i-1}, x_{j-1})\}$
    \EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

The value $d$ is the cost of inserting a gap in one of the sequences, also known as *indel* cost, and $c(y_{i-1}, x_{j-1})$ is the cost associated to change from the state $y_{i-1}$ to $x_{j-1}$, which is defined in a matrix $C$ of size $n \times n$, commonly known as the cost matrix.

Lines 1-7 of the OM algorithm correspond to initialization. Starting with a cost of 0 in $F(1, 1)$, the first row and column of $F$ represent cumulative costs of successively adding gaps. The remaining lines of the algorithm correspond to the row-wise recursion to fill the array $F$ according to the content of the sequences to be compared: at any step of the recursion, the algorithm is looking at a specific pair of indexes (location) and calculating if substitution or insertion/deletion is the cheapest operation. Successively adding the costs of the cheapest operations results in the overall optimal cost for aligning the sequences $X$ and $Y$.

In fact, when $F$ is completely filled, the value in the last cell, i.e. $F(t_X+1, t_Y+1)$ corresponds to the minimal cost of aligning the sequences $X$ and $Y$. It is possible to recover the steps that conduced to this alignment with a traceback from the last cell. However, this is not necessary to obtain the dissimilarities matrix for a set of sequences.


## Example 

Suppose that $S$ is the alphabet and let $X = (S,E,N,D)$ and $Y = (A,N,D)$ be two sequences in $\mathbf{S}$. 

Further, let $d = 2$ and let $c(s_i, s_j)$ be the cost associated to change from state $s_i$ to state $s_j$, for $i, j \in S$. This cost is given by:

$$
c(s_i, s_j) = 
\begin{cases}
0 & \text{if } i=j,\\
3 & \text{otherwise}
\end{cases}
$$

The array $F$ is initialized as follows:

|   |   | S | E | N | D |
|---|---|---|---|---|---|
|   | 0 | 2 | 4 | 6 | 8 |
| A | 2 |   |   |   |   |
| N | 4 |   |   |   |   |
| D | 6 |   |   |   |   |


Then, to fill the second row of $F$ we proceed as follows:

\begin{align*}
F(2,2) &= \min\{F(1, 2)+d, F(2, 1)+d, F(1, 1)+k(y_{1}, x_{1})\} \\
       &= \min\{2+2, 2+2, 0+3\} = 3 \\
F(2,3) &= \min\{F(1, 3)+d, F(2, 2)+d, F(1, 2)+k(y_{1}, x_{2})\} \\
       &= \min\{4+2, 3+2, 2+3\} = 5 \\
F(2,4) &= \min\{F(1, 4)+d, F(2, 3)+d, F(1, 3)+k(y_{1}, x_{3})\} \\
       &= \min\{6+2, 5+2, 4+3\} = 7 \\
F(2,5) &= \min\{F(1, 5)+d, F(2, 4)+d, F(1, 4)+k(y_{1}, x_{4})\} \\
       &= \min\{8+2, 7+2, 6+3\} = 9 
\end{align*}

\par
What yields:

|   |   | S | E | N | D |
|---|---|---|---|---|---|
|   | 0 | 2 | 4 | 6 | 8 |
| A | 2 | 3 | 5 | 7 | 9 |
| N | 4 |   |   |   |   |
| D | 6 |   |   |   |   |

Finally, after completing the recursion for the remaining rows, we obtain the following $F$ array:

|   |   | S | E | N | D |
|---|---|---|---|---|---|
|   | 0 | 2 | 4 | 6 | 8 |
| A | 2 | 3 | 5 | 7 | 9 |
| N | 4 | 5 | 6 | 5 | 7 |
| D | 6 | 7 | 8 | 7 | 5 |

In this simple example, we can easily obtain two optimal (equivalent) alignments without using the algorithm:

S E N D with  

A &ndash; N D or  

&ndash; A N D  
<br>
In both cases we have two matches (cost 0), one mismatch (cost 3) and one gap (cost 2), giving a total cost 5 that is exactly what we obtained in the last cell of $F$.

The cost of inserting a gap ($d$) is also known as *indel* (insert or delete) cost. In this example we can observe that, in order to obtain sequence $X$ from $Y$ we have to **insert** a term (i.e. insert a gap and then change its value to a specific state). Equivalently, to obtain sequence $Y$ starting from $X$ we have to **delete** one term.

The `R` packages `TraMineR` (@TraMineR) and `TraMineRextras` provide several functions to define, analyze and visualize sequential data. In particular, `TraMineR` implements the OM algorithm and offers several methods for computing the cost matrix $C$ and the normalization of the dissimilarity matrix.


## Methods for Calculation of the Cost Matrix

The cost matrix $C$ is a symmetric matrix of size $n \times n$. The value in the $i$-th row and $j$-th column $C[i, j] = c(s_i, s_j)$ indicates the cost of moving from state $s_i$ in time $t > 0$ to state $s_j$ in $t+1$.

The following are the methods available in `TraMineR` to obtain the cost matrix.


### Transition rates (`TRATE`):

The substitution cost between states $s_i$ and $s_j$, $1 \leq i, j \leq n$ is based on the observed relative frequencies of the transitions between the states and is calculated as:

\begin{equation}
\label{eq:transition}
c(s_i, s_j) = a - P(s_i|s_j) - P(s_j|s_i),
\end{equation}

where $P(s_i|s_j)$ is the estimated probability of transition from state $s_j$ in time $t$ to $s_i$ in time $t+1$ and $a$ is a constant, set to a value such that $0 \leq c(s_i, s_j) \leq 2$).

The implementation of this method uses a default value of $a=2$ which results in substitution costs that are close to 2 in sequences where is common to last more than one unit of time in the same state. Additionally, as pointed out by @Studer-2016, the calculation of substitution costs can lead to violations of the triangle inequality, meaning that we obtain a dissimilarity instead of a distance measure.


### Chi-squared distance (`FUTURE`):

The $\chi^2$-distance is a weighted sum of the squared differences of distribution vector frequencies. The weight is given by the inverse of the proportion of the total time spent in the state, meaning that the differences on rare states have higher weights. 

\begin{align}
\label{eq:chisq}
c(s_i, s_j) &= d_{\chi^2}(\mathbf{P_i}, \mathbf{P_j}) \\
            &= \left[ \sum_{l = 1}^n \alpha_l^{-1} \left( P(s_l|s_i) - P(s_l|s_j) \right)^2 \right]^{1/2}
\end{align}

where $\mathbf{P_.} = (P(s_1|s_.), \dots, P(s_n|s_.))'$, and $\alpha_l = \sum_{h=1}^n P(s_l|s_n)$ and $i \neq j$.

It has been shown via simulation, that this distance is particularly sensitive to the time spent in each state but not so much to the order of the states in a sequence (see @Studer-2016).


### Relative frequencies (`INDELS` and `INDELSLOG`):

\begin{equation}
\label{eq:indels_cost}
c(s_i, s_j) = d_i + d_j,
\end{equation}

where the *indel* cost $d_i$ depends on the state and takes values: 

\begin{align}
d_i &= \frac{1}{f_i}, &\text{for method `INDEL`}, \\
d_i &= \log\left({\frac{2}{1+f_i}}\right), &\text{for method `INDELSLOG`}
\end{align}

and $f_i$ is the relative frequency of the state $s_i$ for $i = 1, \dots, n$. 

#### Remarks: 
- For methods `TRATE` and `FUTURE`, the unique *indel* value is $d = max_{1 \leq i,j \leq n} K(i,j)/2$, so that the cost of any change of state is always lower or equal than deleting and inserting an element (or vice versa). The reason behind is that higher *indel* costs, compared to the substitution costs, produce dissimilarities that are greatly affected by time shifts.
- The Needleman-Wunsch algorithm with constant costs for mismatch is known as Levenshtein distance (@Levenshtein-1966), a string metric widely used in computer science.
- In general, the resulting measure of the algorithm is a dissimilarity. However, if the cost matrix fulfills the triangle inequality, we obtain a distance measure (see @Yujian-2007).


## Normalization Methods for Distances

By design, OM can deal with sequences of different lengths via insertions. However, in cases when the lengths of the sequences differ greatly, it can be useful to account for this differences with a normalization factor. 

Given a set two sequences $X, Y \in \mathbf{S}$ of length $t_X$ and $t_Y$, respectively. Let $d(X,Y)$ be the dissimilarity between the sequences $X$ and $Y$, $t_{max}$ the length of the longest sequence in $\mathbf{S}$ and $d_{max}$ the maximum dissimilarity between any pair of sequences in $\mathbf{S}$.

`TraMineR` offers the following options to normalize the dissimilarities between sequences:

- `maxlength`:
$$\frac{d(X,Y)}{t_{max}}$$
- `gmean`: 
$$1- \frac{d_{max}-d(X,Y)}{\sqrt{t_X*t_Y}}$$
- `maxdist`: 
$$\frac{d(X,Y)}{d_{max}}$$


## Example

```{r toy-example, include = FALSE}
toy_seqs <- tibble::tribble(
  ~t1, ~t2, ~t3, ~t4, ~t5,
  "S", "E", "N", "D", NA,
  "A", "N", "D", NA, NA,
  "B", "R", "A", "N", "D", 
  "B", "R", "E", "A", "D",
  "E", "N", "D", NA, NA,
  "R", "E", "D", NA, NA,
  "S", "A", "N", "D", NA,
  "D", "E", "A", "N", NA,
  "A", "B", "E", "S", NA,
  "N", "A", "B", "E", NA
)

toy_alph <- c("A", "B", "D", "E", "N", "R", "S")

toy_sd <- TraMineR::seqdef(
  data = toy_seqs,
  alphabet = toy_alph
)

toy_trate <- TraMineR::seqtrate(toy_sd)

toy_cm <- TraMineR::seqcost(toy_sd, "TRATE")
toy_cm_cmod <- TraMineR::seqcost(toy_sd, "TRATE", cval = 1.2)

dist0 <- TraMineR::seqdist(toy_sd, method = "OM", sm = "TRATE")
dist1 <- TraMineR::seqdist(toy_sd, method = "OM", sm = "TRATE", norm = "maxlength")
dist2 <- TraMineR::seqdist(toy_sd, method = "OM", sm = "TRATE", norm = "gmean")
dist3 <- TraMineR::seqdist(toy_sd, method = "OM", sm = "TRATE", norm = "maxdist")
dist4 <- TraMineR::seqdist(toy_sd, method = "OM", sm = toy_cm_cmod$sm)

toy_dists <- tibble(
  Normalization = rep(c("None", 
                        "None / c=1.2", 
                        "`maxlength`",
                        "`gmean`",
                        "`maxdist`"),
                      each = length(dist0[lower.tri(dist0)])),
  Values = c(dist0[lower.tri(dist0)], 
             dist4[lower.tri(dist0)], 
             dist1[lower.tri(dist0)],
             dist2[lower.tri(dist0)],
             dist3[lower.tri(dist0)])
) %>% 
  group_by(Normalization) %>% 
  summarise(Min = min(Values),
            Max = max(Values),
            Mean = mean(Values),
            Median = median(Values),
            `Std. deviation` = sd(Values)) %>% 
  ungroup()
```

Let $S = \{A, B, D, E, N, R, S\}$ and consider the following sequences in $\mathbf{S}$:

- $(S,E,N,D)$ 
- $(A,N,D)$
- $(B,R,A,N,D)$
- $(B,R,E,A,D)$
- $(E,N,D)$
- $(R,E,D)$
- $(S,A,N,D)$
- $(D,E,A,N)$
- $(A,B,E,S)$
- $(N,A,B,E)$

\par
Table \@ref(tab:toy-trate) shows the transition frequencies or estimated transition probabilities for the observed sequences. For this example, we observe a great amount of cells with the value 0 as there was no observed transition between those states. Additionally, the diagonal was set to 0 as we assume there is no cost associated with a match between two sequences.

```{r toy-trate}
knitr::kable(
  toy_trate,
  row.names = TRUE,
  align = "c",
  digits = 4,
  caption = "Observed transition frequencies."
) %>%
  kableExtra::kable_styling(position = "center")
```

\par
Now, suppose we want to obtain the cost matrix with the method `TRATE` with $a=2$. We would procceed as follows:

\begin{align*}
c(A, B) &= c - P(A|B) - P(B|A) & \\
        &= 2 - `r round(toy_trate[1, 2], 4)` - `r round(toy_trate[2, 1], 4)` = `r round(2-toy_trate[1, 2]-toy_trate[2, 1], 4)` \\
c(A, N) &= c - P(A|N) - P(N|A) & \\
        &= 2 - `r round(toy_trate[1, 5], 4)` - `r round(toy_trate[5, 1], 4)` = `r round(2-toy_trate[1, 5]-toy_trate[5, 1], 4)`
\end{align*}

\par
Table \@ref(tab:toy-cm) shows the full cost matrix obtained from transition probabilities, which is a symmetric matrix. As we can observe, the positions values displayed in $C[1,2], C[1,2], C[1,5], C[5,1]$ are the same as those obtained above.

```{r toy-cm}
knitr::kable(
  toy_cm$sm,
  row.names = TRUE,
  align = "c",
  digits = 4,
  caption = "Cost matrix obtained from transition probabilities."
) %>%
  kableExtra::kable_styling(position = "center")
```

\par
Let us remember that in `TraMineR` the constant is set to 2 by default. Table \@ref(tab:toy-cmod) shows the cost matrix obtained when we set the constant to 1.2, a value just above the maximum sum between the observed frequencies between states.

```{r toy-cmod}
knitr::kable(
  toy_cm_cmod$sm,
  row.names = TRUE,
  align = "c",
  digits = 4,
  caption = "Cost matrix obtained from transition probabilities with $a=1.2$."
) %>%
  kableExtra::kable_styling(position = "center")
```


\par

In addition to changing the value of $a$, we can opt for none or one of the normalization methods mentioned in the previous subsectio in order to obtain the distance matrix. Table \@ref(tab:toy-dists) shows some descriptive statistics of the obtained distances for different methods of normalization.

```{r toy-dists}
knitr::kable(
  toy_dists,
  row.names = FALSE,
  align = "c",
  digits = 4,
  caption = "Comparison of descriptive statistics of the distances for  different approaches of the cost matrix."
) %>%
  kableExtra::kable_styling(position = "center")
```