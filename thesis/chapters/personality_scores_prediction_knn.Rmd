# Personality Scores Prediction with k-Nearest Neighbors

Given a training set $\mathcal{D} = {(x_1, y_1), (x_2, y_2), \dots, (x_n, y_n)}$ of $n$ labeled data points, where $x_i \in \mathbb{R}^d$ and $y_i \in \mathcal{Y}$ (a finite set of class labels for classification or a continuous range of values for regression). $k$-NN provides a way to predict the label or value for a new, data point $x_{n+1}$ (for which $Y$ is unknown) by finding the $k$ training data points closest to $x_{n+1}$ and taking a majority vote of their labels (for classification) or averaging the values of $Y$ (for regression).

There are different ways of calculating the distance between the new data point $x_{n+1}$ and the points in $\mathcal{D}$. For instance, the Euclidean o Mahalanobis distances are usually used. In our case we already count with a matrix distance obtained with OM.

The choice of $k$ is a hyperparameter that can be tuned to optimize the performance of the $k$-NN algorithm. A larger $k$ reduces the effect of noise and outliers, but can also lead to overfitting. A smaller $k$ is more sensitive to noise and outliers, but can better capture local structure.

To compare the performance of different values of $k$, we use the mean squared error (MSE).

\begin{equation}
\text{MSE} = \frac{1}{n} \sum_{i=1}^n (Y_i - \hat{Y}_i)^2
\end{equation}

where $y_i$ is the observed value and $\hat{Y}_i$ is the predicted valua via $k$NN.

In this part of the analysis we only consider the individuals who have available personality scores, that leaves us with a sample size of 200 individuals. We also split the data into two subsets: train (70%) and test (30%). We evaluate the MSE of the predictions for the individuals in the test set but only using the data from the nearest neighbors available in the train set.

The following figure shows for every personality score and different values of $k$ the MSE, i.e. for $k = 1, \dots, 80$ we predict values of $Y$ and compare them with the observed values using the MSE. As a reference, a red line for every personality trait is added to indicate the MSE of the trivial prediction, i.e. the prediction considering all the sample points in the train set.

For agreeableness, the MSE is minimum around $k=50$ and increases again. However, this minimum is not considerably lower than the trivial prediction.

For openness, it is not very clear where the minimum MSE is and the prediction with kNN is always worse than the trivial prediction.

For conscientiousness, extraversion and neuroticism we observe that the MSE decreases as $k$ increases and takes a minimum value (around $k=15$, $k=10$, $k=5$, respectively) thet is considerably lower than the trivial prediction and then the MSE increases again.

```{r, fig.width = (7.5 * 0.8), fig.height = (5.25 * 1.25),  out.width = "250px", fig.align = "center", fig.cap = "MSE by cluster for base setup."}
base_MSE %>%
  filter(k > 3) %>%
  ggplot() +
  geom_line(aes(x = k, y = MSE)) +
  geom_line(
    aes(x = k, y = Trivial, col = "red"),
    alpha = 0.5,
    show.legend = FALSE
  ) +
  facet_wrap(
    facets = vars(Score),
    ncol = 1,
    scales = "free",
    strip.position = "top"
  ) +
  theme_minimal() +
  theme(strip.text = element_text(hjust = 0))
```

## Other set-ups

- Setting the constant $c$ as the maximum of $2 - P(s_i|s_j) - P(s_j|s_i)$ for the calculation of the cost matrix.

```{r, out.width = "350px", fig.align = "center"}
knitr::include_graphics("../../Output/exp1a.pdf")
```

- Using `norm = "gmean"` normalization in `TraMineR::seqdist`.

```{r, out.width = "350px", fig.align = "center"}
knitr::include_graphics("../../Output/exp2a.pdf")
```

- Using `method = "FUTURE"` for the calculation of the cost matrix in `TraMineR::seqcost`.

```{r, out.width = "350px", fig.align = "center"}
knitr::include_graphics("../../Output/exp3a.pdf")
```

- Using `method = "INDELS"` for the calculation of the cost matrix in `TraMineR::seqcost`.

```{r, out.width = "350px", fig.align = "center"}
knitr::include_graphics("../../Output/exp4a.pdf")
```

- Using `method = "INDELSLOG"` for the calculation of the cost matrix in `TraMineR::seqcost`.

```{r, out.width = "350px", fig.align = "center"}
knitr::include_graphics("../../Output/exp5a.pdf")
```

- Using `method = "FUTURE"` for the calculation of the cost matrix in `TraMineR::seqcost` and `norm = "gmean"` normalization in `TraMineR::seqdist`.

```{r, out.width = "350px", fig.align = "center"}
knitr::include_graphics("../../Output/exp6a.pdf")
```

- Using `method = "FUTURE"` and setting the cost of missing to a fixed value in the cost matrix in `TraMineR::seqcost` and `norm = "gmean"` normalization in `TraMineR::seqdist`.

```{r, out.width = "350px", fig.align = "center"}
knitr::include_graphics("../../Output/exp7a.pdf")
```
