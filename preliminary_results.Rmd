---
title: "Categorical sequence analysis with optimal matching: an application to the relationships history of women over 40"
author: 
  - Adriana Clavijo Daza 
institute:
  - Statistics and Data Science Master's, Universität Bern
date: "2022-06-02"
header-includes:
  - \usepackage{algpseudocode}
output: beamer_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
```

```{r libs, echo = FALSE}
library(readxl)
library(tidyr)
library(dplyr)
library(stringr)
library(ggplot2)
library(TraMineR)
library(cluster)
source("predict_scores.R")
source("get_MSE.R")
```


## Motivation

```{r, out.width = "150px", fig.align = "center"}
knitr::include_graphics("../Input/couple.png")
```

Understand the similarities and differences in the romantic relationships history of a group of women over 40 years old and use this information as a predictor of personality traits.


## Women 40+ Healthy Aging Study (i)

```{r, echo = FALSE, out.width= "49%", out.height = "20%", fig.show = "hold", fig.align = "center"}
knitr::include_graphics(c("../Input/logo2.png", "../Input/logo1.png"))
``` 

- Data from 250 individuals collected between June 2017 and February 2018.
- Psychometric instrument to obtain information about the history of romantic relationships of women aged between 40 and 75 years.


## Women 40+ Healthy Aging Study (ii)

- Information about relationship phases starting from the age of 15 years until the current age at the time of the data collection.
- The phases are defined by the start and end age and for each phase and information about civil status, relationship status, living situation, children and quality of the relationship was collected.
- Additional information about the individuals was collected, in particular, scores for personality scores.


## Data example

Consider the relationship status:

```{r, out.width = "300px"}
knitr::include_graphics("../Input/sequence_example1.png")
```
*Current age

- No relationship (NR)
- In a relationship (R)
- Open relationship (OR)
- Changing relationships (CR)


## What is personality?

```{r, out.width = "200px", fig.align = "center"}
knitr::include_graphics("../Input/personality1.png")
```

Personality refers to the enduring characteristics and behavior that comprise a person’s unique adjustment to life, including major traits, interests, drives, values, self-concept, abilities, and emotional patterns.


## The "Big Five" personality traits

```{r, out.width = "300px", fig.align = "center"}
knitr::include_graphics("../Input/personality2.png")
```


## Research question

- Can we get a good prediction of personality scores based on the relationship history sequences?


## Data pre-processing

- Manual corrections of several inconsistent and incomplete records.
- Several additional automatic checks to identify sequences with inconsistent data.
- Corrections based on secondary data source.
- Identification and selection of the variables and patterns that provide a wider perspective of the individuals' situations.
- In total, 239 individuals are considered for the analysis.

```{r, child="data_prep.Rmd"}
```


## Considered states

- 1 = Single + no children
- 2 = Single + children
- 3 = Changing relationships + no children
- 4 = Changing rel. + children
- 5 = Relationship + living apart + no children
- 6 = Relationship + living together + no children 
- 7 = Relationship + living apart + children
- 8 = Relationship + living together + children
- 9 = Married + no children
- 10 = Married + children

```{r, out.width = "280px"}
knitr::include_graphics("../Input/sequence_example2.png")
```

## Distribution of states

```{r final-status, fig.align = "center", out.width = "300px"}
plot5 <- ggplot(data = rh_data, aes(Status_char))
plot5 + geom_bar() + geom_bar() + geom_text(stat = "count", aes(label = ..count..), vjust=-0.25) + scale_x_discrete(guide = guide_axis(n.dodge=2)) + theme(axis.text = element_text(size = 12))
```


## Optimal Matching (OM)

- Technique used in social sciences for the comparison of sequences of categorical states indexed by time.
- Applications on life course and career path analysis. 
- Uses the Needleman-Wunsch algorithm, that was developed to compare biological sequences.
- The Needleman-Wunsch algorithm is an application of dynamic programming, an iterative method that simplifies an optimization problem by breaking it into a recursion of smaller problems.


## Example (i)

Analyzing Sequence Data: Optimal Matching in Management Research (T. Biemann and D. K. Datta)

- Goal: study career paths of deans at US business schools.
- Data source: 149 CVs of deans including public and private business schools.
- Coded into yearly data with the states: administration (A), corporation (C), faculty (F), government (G).

```{r, out.width = "300px", fig.align = "center"}
knitr::include_graphics("../Input/OMA_example0.png")
```

## Example (ii)

Cost matrix:

```{r, out.width = "300px", fig.align = "center"}
knitr::include_graphics("../Input/OMA_example1.png")
```


## Example (iii)

Distance/dissimilarities matrix for five deans:

```{r, out.width = "300px", fig.align = "center"}
knitr::include_graphics("../Input/OMA_example2.png")
```


## Example (iv)

Two of the five resulting clusters:

```{r, out.width = "300px", fig.align = "center"}
knitr::include_graphics("../Input/OMA_example3.png")
```


## The OM algortihm (i)

- Set of $n$ states: $S = \{s_1, \dots, s_n\}$ 
- Sequence of size $t > 0$: $X = (x_1, \dots, x_t)$, with $x_i \in S$ for $i = 1, \dots, t$. 
- $\mathbf{S}$ is the set of all possible sequences with states belonging to $S$.

*Objective:* Find the optimal way to align these two sequences

- Let $X, Y \in \mathbf{S}$ be two sequences of size $t_1$ and $t_2$, respectively. 
- Define an empty array $F$ of size $(t_1+1) \times (t_2+1)$


## The OM algortihm (ii)

\begin{algorithmic}[1]
\State $F(1, 1) \gets 0$
\For{$j \gets 2,t_2+1$}
  \State $F(1,j) \gets F(1, j-1) + d$
\EndFor
\For{$i \gets 2,t_1+1$}
  \State $F(i,1) \gets F(i-1, 1) + d$
\EndFor
\For{$i \gets 2,t_1+1$}
  \For{$j \gets 2,t_2+1$}
    \State $F(i,j) \gets \min\{F(i-1, j)+d, F(i, j-1)+d, F(i-1, j-1)+k(y_{i-1}, x_{j-1})\}$
    \EndFor
\EndFor
\end{algorithmic}


## The OM algortihm (iii)

- $d$ is the cost of inserting a gap (indel cost). 
- $k(y_{i-1}, x_{j-1})$ is the cost associated to change from the state $y_{i-1}$ to $x_{j-1}$.
- These costs are defined in a matrix $K$ of size $n \times n$ $\rightarrow$ cost matrix.
- Lines 1-7 of the algorithm correspond to initialization.
- The remaining lines of the algorithm correspond to the row-wise recursion to fill the array $F$.
- When $F$ is completely filled, the value $F(t_1+1, t_2+1)$ corresponds to the optimal cost of aligning the sequences $X$ and $Y$.


## Cost matrix (i)

The `R` package `TraMineR` provides several functions to work with sets of sequences. The package implements OM and offers several methods for computing the cost matrix $K$.


## Cost matrix (ii)

- Transition rates (`TRATE`):

The substitution cost between states $s_i$ and $s_j$, $1 \leq i, j \leq n$, is calculated as:

\begin{equation}
\label{eq:transition}
K(s_i, s_j) = c - P(s_i|s_j) - P(s_j|s_i),
\end{equation}

where $P(s_i|s_j)$ is the probability of transition from state $s_j$ in time $t$ to $s_i$ in time $t+1$ and $c$ is a constant, set to a value such that $0 \leq K(s_i, s_j) \leq 2$).


## Cost matrix (iii)

- Chi-squared distance (`FUTURE`):

\begin{equation}
\label{eq:chisq}
K(s_i, s_j) = ChiDist(\mathbf{P_i}, \mathbf{P_j}),
\end{equation}

where $\mathbf{P_.} = (P(s_1|.), \dots, P(s_n|.))'$


## Cost matrix (iv)

- Relative frequencies (`INDELS` and `INDELSLOG`):

\begin{equation}
\label{eq:indels}
K(s_i, s_j) = indel_i + indel_j,
\end{equation}

where $indel_i = 1/f_i$ for method `INDEL`, $indel_i = \log[2/(1+f_i)]$ and $f_i$ is the relative frequency of the state $s_i$ for $i = 1, \dots, n$. 


## Example (i)

- $S$ = the alphabet
- $X = \{S,E,N,D\}, Y = \{A,N,D\} \in \mathbf{S}$
- $d = 2$  

$$
K(i,j) = 
\begin{cases}
0 & \text{if } i=j,\\
3 & \text{otherwise}
\end{cases}
$$


## Example (ii)

|   |   | S | E | N | D |
|---|---|---|---|---|---|
|   | 0 | 2 | 4 | 6 | 8 |
| A | 2 |   |   |   |   |
| N | 4 |   |   |   |   |
| D | 6 |   |   |   |   |

- $F(2,2) = min\{F(1, 2)+d, F(2, 1)+d, F(1, 1)+k(y_{1}, x_{1})\} = min\{2+2, 2+2, 0+3\} = 3$
- $F(2,3) = min\{F(1, 3)+d, F(2, 2)+d, F(1, 2)+k(y_{1}, x_{2})\} = min\{4+2, 3+2, 2+3\} = 5$
- $F(2,4) = min\{F(1, 4)+d, F(2, 3)+d, F(1, 3)+k(y_{1}, x_{3})\} = min\{6+2, 5+2, 4+3\} = 7$
- $F(2,5) = min\{F(1, 5)+d, F(2, 4)+d, F(1, 4)+k(y_{1}, x_{4})\} = min\{8+2, 7+2, 6+3\} = 9$


## Example (iii)

|   |   | S | E | N | D |
|---|---|---|---|---|---|
|   | 0 | 2 | 4 | 6 | 8 |
| A | 2 | 3 | 5 | 7 | 9 |
| N | 4 |   |   |   |   |
| D | 6 |   |   |   |   |


- $F(3,2) = min\{F(2, 2)+d, F(3, 1)+d, F(2, 1)+k(y_{2}, x_{1})\} = min\{3+2, 4+2, 2+3\} = 5$
- $F(3,3) = min\{F(2, 3)+d, F(3, 2)+d, F(2, 2)+k(y_{2}, x_{2})\} = min\{5+2, 5+2, 3+3\} = 6$
- $\dots$


## Cost matrix (ii)

```{r cost-matrix, echo=FALSE, message=FALSE}
test <- seqformat(rh_data, from = "SPELL", to = "STS",
                  id = "Id", begin = "Start_age", end = "End_age", 
                  status = "Status", covar = "Age", process = FALSE)

alphabet <- as.character(1:10)

my_seq <- seqdef(test, alphabet = alphabet)

cost_matrix_1 <- seqsubm(my_seq, method = "TRATE", with.missing = TRUE)
```

```{r, out.width = "300px", fig.align = "center"}
knitr::include_graphics("../Output/cost_matrix.png")
```


## Distance matrix

- Given $x, y \in X$ two sequences of interest. There different mappings from $T: X \to X$ such that $T(x) = y$. 
- $T$ is composed of elements (operations) that can be insertion, deletion or substitution.
- There is a cost associated with each operation: The substitution cost are given by the cost matrix and insertion/deletion costs are set in a way that reduces/increases the importance of time shifts (low/high).
- The distance between $x$ and $y$ is given by the lower cost mapping.

```{r, echo=FALSE, message=FALSE}
my_dist <- seqdist(my_seq, method = "OM", sm = cost_matrix_1, with.missing = TRUE)
```


## Clustering (i)

- Hierarchical method: Agglomerative Nesting (AGNES).
- At the beginning each individual is a cluster and, at every step, the closest clusters are merged together.
- Distance between two clusters is the average of the distances between the points in one cluster and the points in the other cluster.

```{r, echo=FALSE, message=FALSE}
clusterward <- agnes(my_dist, diss = TRUE, method = "ward")
```


## Clustering (ii)

Dendrogram:

```{r, out.width="300px", fig.align="center"}
plot(clusterward, which.plots = 2, main = "Dendrogram")
abline(h = 153, col = "red")
```


## Clustering (iii)

```{r, echo=FALSE, message=FALSE, cache=TRUE}
clusterward <- agnes(my_dist, diss = TRUE, method = "ward")

clusters <- cutree(clusterward, k = 5)

clusters_labels <- factor(clusters, labels = paste("Cluster", 1:5))
```

```{r, out.width = "320px", fig.align = "center"}
#knitr::include_graphics("../Output/cluster2.png")
par(mar = c(2, 1.7, 0.75, 0.5))
seqdplot(my_seq, group = clusters_labels, border = NA, 
         ltext = status_labels)
dev.off()
```


## Descriptive statistics of personality scores

```{r, echo=FALSE, message=FALSE}
BFI_data <- read_excel("../Data_original/Adriana_BFI.xlsx")

BFI_data <- BFI_data %>% 
  select(PersCode,
         starts_with("BFI"))

pers_descrip <- BFI_data %>% 
  select(PersCode,
         ends_with("mean")) %>% 
  pivot_longer(cols = ends_with("mean"), 
               names_to = "Personality trait", 
               values_to = "Value") %>% 
  group_by(`Personality trait`) %>% 
  summarise(Min = min(Value, na.rm = TRUE),
            Max = max(Value, na.rm = TRUE),
            Average = mean(Value, na.rm = TRUE),
            `Std. deviation` = sd(Value, na.rm = TRUE)) %>% 
  ungroup()

pers_descrip[, 1] <- c("Agreeablenes", "Conscientiousness",
                       "Extraversion", "Neuroticism", "Openness")

knitr::kable(pers_descrip, digits = 2) %>% 
  kableExtra::kable_styling(font_size = 8)
```


## Average personality scores by cluster

```{r, echo=FALSE, message=FALSE}
all_data <- tibble(Id = colnames(my_dist), Cluster = clusters_labels) %>% 
  left_join(BFI_data, by = c("Id" = "PersCode")) %>% 
  select(Id, Cluster, ends_with("mean"))

by_cluster <- all_data %>% 
  group_by(Cluster) %>% 
  summarise(Extraversion = mean(BFI_extraversion_mean, na.rm = TRUE),
            Agreeableness = mean(BFI_agreeableness_mean, 
                                         na.rm = TRUE),
            Conscientiousness = mean(BFI_conscientiousness_mean,
                                             na.rm = TRUE),
            Neuroticism = mean(BFI_neuroticism_mean, na.rm = TRUE),
            Openness = mean(BFI_openness_mean, na.rm = TRUE)) %>% 
  ungroup()

knitr::kable(by_cluster, digits = 2) %>% 
  kableExtra::kable_styling(font_size = 7)
```

Subjective description of the clusters:

- Cluster 1: Married with children then divorced/widowed
- Cluster 2: Sequences with more changes (unstable)
- Cluster 3: Younger, not married with children
- Cluster 4: Not married w/o children
- Cluster 5: Married w/o children

## k-Nearest Neighbors (kNN) algorithm

- It's a non-parametric method.
- Choose the $k$ nearest samples to an individual (distance matrix).
- Calculate the average of the variable of interest with the $k$ samples $\rightarrow$ prediction.
- Use a measure such as $MSE$ to select the optimal $k$.

$$ MSE = \frac{1}{n} \sum_{i=1}^n (Y_i - \hat{Y}_i)^2, $$

where $n$ is the number of data points considered, $Y_i$ is the observed value and $\hat{Y}_i$ is the predicted value.

## k-Nearest Neighbors

```{r, echo=FALSE, message=FALSE, cache=TRUE}
set.seed(123)
n <- dim(all_data)[1]
size <- round(n*0.3)

test_set <- sample.int(n, size)
train_set <- 1:n
train_set <- train_set[-test_set]

test_names <- colnames(my_dist)[test_set]
train_names <- colnames(my_dist)[train_set]

find_neighbors <- function(i, matrix, k){
  data <- sort(matrix[i, ])[-1][1:k]
  return(names(data))
}

preditc_scores <- function(data, neighbors){
  predictions <- data %>% 
    filter(Id %in% neighbors) %>% 
    summarise(Extraversion = mean(BFI_extraversion_mean, na.rm = TRUE),
              Agreeableness = mean(BFI_agreeableness_mean, na.rm = TRUE),
              Conscientiousness = mean(BFI_conscientiousness_mean, na.rm = TRUE),
              Neuroticism = mean(BFI_neuroticism_mean, na.rm = TRUE),
              Openness = mean(BFI_openness_mean, na.rm = TRUE)) %>% 
    as.vector() %>% 
    unlist()
  return(predictions)
}

K <- 30
results_train <- list()

for(k in 1:K){
all_neighbors_train <- list()

for(i in seq_along(train_set)){
  all_neighbors_train[[i]] <- find_neighbors(train_set[i], matrix = my_dist, k = k)
}

names(all_neighbors_train) <- train_names

all_predictions_train <- list()

for(i in seq_along(train_set)){
  all_predictions_train[[i]] <- preditc_scores(all_data, neighbors = all_neighbors_train[[i]])
}

names(all_predictions_train) <- train_names

predictions_train_df <- do.call(rbind.data.frame, all_predictions_train)

colnames(predictions_train_df) <- names(all_predictions_train[[1]])

predictions_train_df[, "Id"] <- train_names

sq_error_train <- predictions_train_df %>% 
  left_join(all_data, by = "Id") %>% 
  mutate(sq_diff_Extraversion = (Extraversion - BFI_extraversion_mean)^2,
         sq_diff_Agreeableness = (Agreeableness - BFI_agreeableness_mean)^2,
         sq_diff_Conscientiousness = (Conscientiousness - BFI_conscientiousness_mean)^2,
         sq_diff_Neuroticism = (Neuroticism - BFI_neuroticism_mean)^2,
         sq_diff_Openness = (Openness - BFI_openness_mean)^2) %>% 
  select(Id, Cluster, starts_with("sq_diff")) %>% 
  pivot_longer(starts_with("sq_diff"), names_to = "Score", values_to = "Value") %>% 
  group_by(Score) %>% 
  summarise(MSQ = mean(Value, na.rm = TRUE)) %>% 
  ungroup()

colnames(sq_error_train)[2] <- paste0("MSQ_", k)

sq_error_train[, 1] <- c("Agreeablenes", "Conscientiousness",
                        "Extraversion", "Neuroticism", "Openness")

results_train[[k]] <- sq_error_train
}

train_MSQ <- results_train %>% 
  purrr::reduce(left_join, by = "Score") %>% 
  pivot_longer(starts_with("MSQ_"), names_prefix = "MSQ_", names_to = "k", 
               values_to = "MSE") %>% 
  mutate(k = as.numeric(k))
```

```{r, echo=FALSE, message=FALSE, out.width = "300px", fig.align = "center"}
ggplot(data = train_MSQ, aes(x = k, y = MSE, col = Score)) +
  geom_line()
```


## What's next?

- Use the kNN predictions to tune the parameters used in the specification of the cost matrix (e.g. indel cost, transition cost calculation)
- Try other prediction methods (e.g. distance-based linear models)


## References

- Sequence Analysis: New Methods for Old Ideas - A. Abbott (1995)
- Optimal Matching Analysis: A Methodological Note on Studying Career Mobility - T. W. Chan (1995)
- Analyzing Sequence Data: Optimal Matching in
Management Research - T. Biemann & D. K. Datta (2013)
- Analyzing and Visualizing State Sequences in R
with TraMineR - A. Gabadinho, G. Ritschard, N. S. Müller, M. Studer (2011)